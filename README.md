# smiles-credit-score
(Постановка задачи)[https://drive.google.com/file/d/17MwB1rnwf0Hz96drkATegfYp27wlC4J6/view]

Дополнительно от руководителя:
Кредитный скоринг — важнейшая банковская задача. Стандартным подходом к ее решению является построение классических моделей машинного обучения, таких как логистическая регрессия и градиентный бустинг на табличных данных, в том числе используя агрегации последовательных данных, например, транзакционных историй клиентов. Данный подход рабочий, но при агрегации неизбежно теряется часть важной информации о поведении клиента. Альтернативный подход заключается в использовании последовательных данных «как есть», подавая их на вход рекуррентной нейронной сети или трансформеру.

Использование RNN-like архитектур для данной задачи хорошо изучено и показывает отличные результаты. Опыт соревнований показывает, что побить GRU/LSTM трансформером в данной задаче крайней затруднительно, что в эру трансформеров порождает попытки улучшить существующие архитектуры обоих подходов.

**Описание и цели**

Улучшение существующих архитектур для решения ряда задач на последовательных данных (в первую очередь кредитного скоринга) — важная задача, ведь прирост  в 1 п.п. целевой метрики в зависимости от масштаба банка может измеряться сотнями миллионов рублей прибыли.

Целью работы является исследование современных нейросетевых подходов для предсказания дефолта на последовательных данных кредитных историй.

**Конкретные задачи**

1. Собрать бейзлайны, предоставленные организаторами, выделить обучающую и валидационную выборки,обучить модель и замерить метрики

2. С помощью rnn-like архитектур постараться улучшить бейзлайн > 0.3 п.п. Gini

3. С помощью transformer-like архитектур постараться улучшить бейзлайн > 0.3 п.п. Gini

**Завершенность проекта в зависимости от задач:**

**1 - 50% 1-2 - 80% 1-3 100%**

**Ссылки на ресурсы (datasetets, github repos)**

https://github.com/SmirnovValeriy/dl-fintech-bki/tree/master

https://github.com/smirnovevgeny/AlfaBattle2.0/tree/master

RWKV: Reinventing RNNs for the Transformer Era

https://arxiv.org/abs/2305.13048

xLSTM: Extended Long Short-Term Memory

https://arxiv.org/abs/2405.04517

Mamba: Linear-Time Sequence Modeling with Selective State Spaces

https://arxiv.org/abs/2312.00752
