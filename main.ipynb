{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports and requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В данном соревновании мы имеем дело с последовательностями, один из интуитивных способов работы с ними &ndash; использование рекуррентных нейронных сетей. В этом базовом решении мы демонстрируем, как можно построить хорошее решение задачи соревнования без использования сложного и трудоемкого feature engineering'а (чтобы эффективно решать ту же задачу с высоким качеством с помощью бустингов нужно несколько тысяч признаков), благодаря рекуррентным нейронным сетям. В этом ноутбуке мы построим решение с использованием фреймфорка `torch`. Для комфортной работы Вам понадобится машина с `GPU` (хватит ресурсов `google colab` или `kaggle`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "\n",
    "# !!! измените \"2\" на номер доступной вам сuda\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# добавим родительскую директорию, в ней лежат все необходимые полезные функции для обработки данных\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.style.use(\"seaborn-pastel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA_PATH = \"/trinity/home/team08/workspace/data/train_data/\"\n",
    "# TEST_DATA_PATH = \"/trinity/home/team08/workspace/data/test_data/\"\n",
    "\n",
    "# TRAIN_TARGET_PATH = \"/trinity/home/team08/workspace/data/train_target.csv\"\n",
    "# TEST_TARGET_PATH = \"/trinity/home/team08/workspace/data/test_target.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Разделение завершено. Файлы сохранены.\n",
      "Разделение завершено. Файлы сохранены.\n"
     ]
    }
   ],
   "source": [
    "# Загрузка Parquet файла\n",
    "file_path = '/trinity/home/team08/workspace/data/train_data/train_data_0.pq'\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# Группировка данных по пользователю\n",
    "user_groups = df.groupby('id')\n",
    "\n",
    "# Создание списка групп\n",
    "grouped_data = [group for _, group in user_groups]\n",
    "\n",
    "# Определение размера каждой части\n",
    "total_groups = len(grouped_data)\n",
    "part_size = total_groups // 12\n",
    "\n",
    "# Разделение на 12 частей, избегая разбиения истории одного пользователя\n",
    "parts = []\n",
    "for i in range(12):\n",
    "    start_index = i * part_size\n",
    "    end_index = (i + 1) * part_size if i < 11 else total_groups\n",
    "    part = pd.concat(grouped_data[start_index:end_index])\n",
    "    parts.append(part)\n",
    "\n",
    "output_dir = '/trinity/home/team08/workspace/main_project/train_data'\n",
    "os.makedirs(output_dir, exist_ok = True)\n",
    "\n",
    "# Сохранение каждой части в отдельный Parquet файл\n",
    "for i, part in enumerate(parts):\n",
    "    part_file_path = os.path.join(output_dir, f'part_{i+1}.pqt')\n",
    "    part.to_parquet(part_file_path)\n",
    "\n",
    "print(\"Разделение завершено. Файлы сохранены.\")\n",
    "\n",
    "TRAIN_DATA_PATH = \"/trinity/home/team08/workspace/main_project/train_data/\"\n",
    "\n",
    "# Загрузка Parquet файла\n",
    "file_path = '/trinity/home/team08/workspace/data/test_data/test_data_0.pq'\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# Группировка данных по пользователю\n",
    "user_groups = df.groupby('id')\n",
    "\n",
    "# Создание списка групп\n",
    "grouped_data = [group for _, group in user_groups]\n",
    "\n",
    "# Определение размера каждой части\n",
    "total_groups = len(grouped_data)\n",
    "part_size = total_groups // 2\n",
    "\n",
    "# Разделение на 2 части, избегая разбиения истории одного пользователя\n",
    "parts = []\n",
    "for i in range(2):\n",
    "    start_index = i * part_size\n",
    "    end_index = (i + 1) * part_size if i < 1 else total_groups\n",
    "    part = pd.concat(grouped_data[start_index:end_index])\n",
    "    parts.append(part)\n",
    "\n",
    "output_dir = '/trinity/home/team08/workspace/main_project/test_data'\n",
    "os.makedirs(output_dir, exist_ok = True)\n",
    "\n",
    "# Сохранение каждой части в отдельный Parquet файл\n",
    "for i, part in enumerate(parts):\n",
    "    part_file_path = os.path.join(output_dir, f'part_{i+1}.pqt')\n",
    "    part.to_parquet(part_file_path)\n",
    "\n",
    "print(\"Разделение завершено. Файлы сохранены.\")\n",
    "\n",
    "TEST_DATA_PATH = \"/trinity/home/team08/workspace/main_project/test_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"pre_since_opened\", \"pre_since_confirmed\", \"pre_pterm\", \"pre_fterm\", \"pre_till_pclose\", \"pre_till_fclose\",\n",
    "            \"pre_loans_credit_limit\", \"pre_loans_next_pay_summ\", \"pre_loans_outstanding\", \"pre_loans_total_overdue\",\n",
    "            \"pre_loans_max_overdue_sum\", \"pre_loans_credit_cost_rate\",\n",
    "            \"pre_loans5\", \"pre_loans530\", \"pre_loans3060\", \"pre_loans6090\", \"pre_loans90\",\n",
    "            \"is_zero_loans5\", \"is_zero_loans530\", \"is_zero_loans3060\", \"is_zero_loans6090\", \"is_zero_loans90\",\n",
    "            \"pre_util\", \"pre_over2limit\", \"pre_maxover2limit\", \"is_zero_util\", \"is_zero_over2limit\", \"is_zero_maxover2limit\",\n",
    "            \"enc_paym_0\", \"enc_paym_1\", \"enc_paym_2\", \"enc_paym_3\", \"enc_paym_4\", \"enc_paym_5\", \"enc_paym_6\", \"enc_paym_7\", \"enc_paym_8\",\n",
    "            \"enc_paym_9\", \"enc_paym_10\", \"enc_paym_11\", \"enc_paym_12\", \"enc_paym_13\", \"enc_paym_14\", \"enc_paym_15\", \"enc_paym_16\",\n",
    "            \"enc_paym_17\", \"enc_paym_18\", \"enc_paym_19\", \"enc_paym_20\", \"enc_paym_21\", \"enc_paym_22\", \"enc_paym_23\", \"enc_paym_24\",\n",
    "            \"enc_loans_account_holder_type\", \"enc_loans_credit_status\", \"enc_loans_credit_type\", \"enc_loans_account_cur\",\n",
    "            \"pclose_flag\", \"fclose_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20827</th>\n",
       "      <td>20827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20828</th>\n",
       "      <td>20828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20829</th>\n",
       "      <td>20829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20830</th>\n",
       "      <td>20830</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20831</th>\n",
       "      <td>20831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20832 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  flag\n",
       "0          0     0\n",
       "1          1     0\n",
       "2          2     0\n",
       "3          3     0\n",
       "4          4     0\n",
       "...      ...   ...\n",
       "20827  20827     0\n",
       "20828  20828     0\n",
       "20829  20829     0\n",
       "20830  20830     0\n",
       "20831  20831     0\n",
       "\n",
       "[20832 rows x 2 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = pd.read_csv(TRAIN_TARGET_PATH)\n",
    "train_target = train_target.iloc[:20832]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>3499995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>3499996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>3499997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>3499998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>3499999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id\n",
       "0       3000000\n",
       "1       3000001\n",
       "2       3000002\n",
       "3       3000003\n",
       "4       3000004\n",
       "...         ...\n",
       "499995  3499995\n",
       "499996  3499996\n",
       "499997  3499997\n",
       "499998  3499998\n",
       "499999  3499999\n",
       "\n",
       "[500000 rows x 1 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target = pd.read_csv(TEST_TARGET_PATH)\n",
    "test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Как и в случае с бустингами, мы не можем поместить всю выборку в память ввиду, например, ограниченных ресурсов. Для итеративного чтения данных нам потребуется функция `utils.read_parquet_dataset_from_local`, которая читает N частей датасета за раз в память.\n",
    "\n",
    "\n",
    "* Нейронные сети требуют отдельного внимания к тому, как будут предобработаны и поданы данные. Важные моменты, на которые требуется обратить внимание:\n",
    "    1. Использование рекуррентных сетей подразумевает работу на уровне последовательностей, где одна последовательность &ndash; все исторические кредиты клиента. Чтобы преобразовать `pd.DataFrame` с записями из кредитных историй клиентов в табличном виде к последовательностям, мы подготовили функцию `dataset_preprocessing_utils.transform_credits_to_sequences`, она производит необходимые манипуляции и возвращает фрейм с двумя колонками: `id` и `sequences`. Колонка `sequences` представляет из себя список списков длины `len(features)`, где каждый вложенный список &ndash; значения одного конкретного признака во всех кредитах клиента. \n",
    "    \n",
    "    2. Клиенты могут иметь различные по длине кредитные истории. При этом обучение нейронных сетей происходит батчами и поскольку рекуррентные слои не способны обрабатывать батчи с последовательностями  неодинаковой длины, существует несколько подходов для приведения последовтельностей в батче к удобоваримому виду. Простой подход заключается в дополнении более коротких последовательностей нулями до максимальной длины последовательности в батче (т. н. паддинг). Довольно неэффективно делать паддинг внутри батча на последовательностях случайной длины (часто будем делать большой и бесполезный паддинг). Гораздо лучше использовать технику `Sequence Bucketing` (о ней мы рассказываем в нашем треке). Для реализации паддинга последовательностей кредитов клиентов мы подготовили функцию `dataset_preprocessing_utils.create_padded_buckets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def read_parquet_dataset_from_local(path_to_dataset: str, start_from: int = 0, num_parts_to_read: int = 2, \n",
    "                                    columns: List[str] = None, verbose: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Читает ``num_parts_to_read`` партиций и преобразует их к pandas.DataFrame.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    path_to_dataset: str\n",
    "        Путь до директории с партициями.\n",
    "    start_from: int, default=0\n",
    "        Номер партиции, с которой начать чтение.\n",
    "    num_parts_to_read: int, default=2\n",
    "        Число партиций, которые требуется прочитать.\n",
    "    columns: List[str], default=None\n",
    "        Список колонок, которые нужно прочитать из каждой партиции. Если None, то считываются все колонки.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    ----------------------\n",
    "    frame: pandas.DataFrame\n",
    "        Прочитанные партиции, преобразованные к pandas.DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    start_from = max(0, start_from)\n",
    "    # dictionory of format {partition number: partition filename}\n",
    "    dataset_paths = {int(os.path.splitext(filename)[0].split(\"_\")[-1]): os.path.join(path_to_dataset, filename)\n",
    "                     for filename in os.listdir(path_to_dataset)}\n",
    "    chunks = [dataset_paths[num] for num in sorted(dataset_paths.keys()) if num>=start_from][:num_parts_to_read]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Reading chunks:\", *chunks, sep=\"\\n\")\n",
    "    for chunk_path in tqdm.tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n",
    "        chunk = pd.read_parquet(chunk_path, columns=columns)\n",
    "        res.append(chunk)\n",
    "    return pd.concat(res).reset_index(drop=True)\n",
    "\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "def pad_sequence(array: np.ndarray, max_len: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Принимает на вход массив массивов ``array`` и производит padding каждого вложенного массива до ``max_len``.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    array: numpy.ndarray\n",
    "        Входной массив массивов.\n",
    "    max_len: int\n",
    "        Длина, до которой нужно сделать padding вложенных массивов.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    ----------------------\n",
    "    output: numpy.ndarray\n",
    "        Выходной массив.\n",
    "    \"\"\"\n",
    "    if isinstance(max_len, float):\n",
    "        print(max_len)\n",
    "    output = np.zeros((len(features), max_len))\n",
    "    output[:, :array.shape[1]] = array\n",
    "    return output\n",
    "\n",
    "\n",
    "def truncate(x, num_last_credits: int = 0):\n",
    "    return pd.Series({\"sequences\": x.values.transpose()[:, -num_last_credits:]})\n",
    "\n",
    "\n",
    "def transform_credits_to_sequences(credits_frame: pd.DataFrame,\n",
    "                                   num_last_credits: int = 0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Принимает pandas.DataFrame с записями кредитных историй клиентов, сортирует кредиты по клиентам\n",
    "    (внутри клиента сортирует кредиты от старых к новым), берет ``num_last_credits`` кредитов,\n",
    "    возвращает новый pandas.DataFrame с двумя колонками: id и sequences.\n",
    "    Каждое значение в столбце sequences - это массив массивов.\n",
    "    Каждый вложенный массив - значение одного признака во всех кредитах клиента.\n",
    "    Всего признаков len(features), поэтому будет len(features) массивов.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    credits_frame: pandas.DataFrame\n",
    "        Датафрейм с записями кредитных историй клиентов.\n",
    "    num_last_credits: int, default=0\n",
    "         Количество кредитов клиента, которые будут включены в выходные данные. Если 0, то берутся все кредиты.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    ----------------------\n",
    "    output: pandas.DataFrame\n",
    "        Выходной датафрейм с двумя столбцами: \"id\", \"sequences\".\n",
    "    \"\"\"\n",
    "    return credits_frame \\\n",
    "        .sort_values([\"id\", \"rn\"]) \\\n",
    "        .groupby([\"id\"])[features] \\\n",
    "        .apply(lambda x: truncate(x, num_last_credits=num_last_credits)) \\\n",
    "        .reset_index()\n",
    "\n",
    "\n",
    "def create_padded_buckets(frame_of_sequences: pd.DataFrame, bucket_info: Dict[int, int],\n",
    "                          save_to_file_path: str = None, has_target: bool = True):\n",
    "    \"\"\"\n",
    "    Реализует Sequence Bucketing технику для обучения рекуррентных нейронных сетей.\n",
    "    Принимает на вход датафрейм ``frame_of_sequences`` с двумя столбцами: \"id\", \"sequences\"\n",
    "    (результат работы функции transform_credits_to_sequences),\n",
    "    словарь ``bucket_info``, где для последовательности каждой длины указано, до какой максимальной длины нужно делать\n",
    "    padding, группирует кредиты по бакетам (на основе длины), производит padding нулями и сохраняет результат\n",
    "    в pickle файл, если требуется.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    frame_of_sequences: pandas.DataFrame\n",
    "        Входной датафрейм с двумя столбцами \"id\", \"sequences\" (результат работы функции transform_credits_to_sequences).\n",
    "    bucket_info: Dict[int, int]\n",
    "        Cловарь, где для последовательности каждой длины указано, до какой максимальной длины нужно делать padding.\n",
    "    save_to_file_path: str, default=None\n",
    "        Опциональный путь до файла, куда нужно сохранить результат. Если None, то сохранение не требуется.\n",
    "    has_target: bool, deafult=True\n",
    "        Флаг, есть ли в frame_of_sequences целевая переменная или нет. Если есть, то она также будет записана в выходной словарь.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    ----------------------\n",
    "    dict_result: dict\n",
    "        Выходной словарь со ключами:  \"id\", \"padded_sequences\", \"target\".\n",
    "    \"\"\"\n",
    "    frame_of_sequences[\"sequence_length\"] = frame_of_sequences[\"sequences\"].apply(lambda x: len(x[1]))\n",
    "    frame_of_sequences[\"bucket_idx\"] = frame_of_sequences[\"sequence_length\"].map(bucket_info)\n",
    "    padded_seq = []\n",
    "    targets = []\n",
    "    ids = []\n",
    "\n",
    "    for size, bucket in tqdm.notebook.tqdm(frame_of_sequences.groupby(\"bucket_idx\"), desc=\"Extracting buckets\"):\n",
    "        padded_sequences = bucket[\"sequences\"].apply(lambda x: pad_sequence(x, size)).values\n",
    "        padded_seq.append(np.stack(padded_sequences, axis=0))\n",
    "\n",
    "        if has_target:\n",
    "            targets.append(bucket[\"flag\"].values)\n",
    "\n",
    "        ids.append(bucket[\"id\"].values)\n",
    "\n",
    "    frame_of_sequences.drop(columns=[\"bucket_idx\"], inplace=True)\n",
    "\n",
    "    dict_result = {\n",
    "        \"id\": np.array(ids, dtype=np.object_),\n",
    "        \"padded_sequences\": np.array(padded_seq, dtype=np.object_),\n",
    "        \"target\": np.array(targets, dtype=np.object_) if targets else []\n",
    "    }\n",
    "\n",
    "    if save_to_file_path:\n",
    "        with open(save_to_file_path, \"wb\") as f:\n",
    "            pickle.dump(dict_result, f)\n",
    "    return dict_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В дальнейшем при построении рекуррентной нейронной сети нам понадобятся следующие статистики по тренировочной и тестовой выборкам: распределение длин кредитных историй и число уникальных значений каждого категориального значения. Посчитаем эти статистики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count statistics on train data:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "/trinity/home/team08/workspace/main_project/train_data/part_1.pqt\n",
      "/trinity/home/team08/workspace/main_project/train_data/part_2.pqt\n",
      "/trinity/home/team08/workspace/main_project/train_data/part_3.pqt\n",
      "/trinity/home/team08/workspace/main_project/train_data/part_4.pqt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_313592/248440550.py:38: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for chunk_path in tqdm.tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1b893705fb4f8b871c04b49066170c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count statistics on train data:  33%|███▎      | 1/3 [00:00<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "/trinity/home/team08/workspace/main_project/train_data/part_4.pqt\n",
      "/trinity/home/team08/workspace/main_project/train_data/part_5.pqt\n",
      "/trinity/home/team08/workspace/main_project/train_data/part_6.pqt\n",
      "/trinity/home/team08/workspace/main_project/train_data/part_7.pqt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_313592/248440550.py:38: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for chunk_path in tqdm.tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a2273968564e6d99adcb01350fd83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count statistics on train data:  67%|██████▋   | 2/3 [00:00<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "/trinity/home/team08/workspace/main_project/train_data/part_8.pqt\n",
      "/trinity/home/team08/workspace/main_project/train_data/part_9.pqt\n",
      "/trinity/home/team08/workspace/main_project/train_data/part_10.pqt\n",
      "/trinity/home/team08/workspace/main_project/train_data/part_11.pqt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_313592/248440550.py:38: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for chunk_path in tqdm.tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4891f6e78fb34309b4be5eda56543290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count statistics on train data: 100%|██████████| 3/3 [00:01<00:00,  2.80it/s]\n",
      "Count statistics on test data:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunks:\n",
      "/trinity/home/team08/workspace/main_project/test_data/part_1.pqt\n",
      "/trinity/home/team08/workspace/main_project/test_data/part_2.pqt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_313592/248440550.py:38: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for chunk_path in tqdm.tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04b92012bd44929b652d3fabd713e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count statistics on test data: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.5 s, sys: 2.26 s, total: 6.76 s\n",
      "Wall time: 2.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "\n",
    "train_lens = []\n",
    "test_lens = []\n",
    "uniques = defaultdict(set)\n",
    "\n",
    "for step in tqdm.tqdm(range(0, 12, 4),\n",
    "                     desc=\"Count statistics on train data\"):\n",
    "        credits_frame = read_parquet_dataset_from_local(TRAIN_DATA_PATH, step, 4, verbose=True)\n",
    "        seq_lens = credits_frame.groupby(\"id\").agg(seq_len=(\"rn\", \"max\"))[\"seq_len\"].values\n",
    "        train_lens.extend(seq_lens)\n",
    "        credits_frame.drop(columns=[\"id\", \"rn\"], inplace=True)\n",
    "        for feat in credits_frame.columns.values:\n",
    "            uniques[feat] = uniques[feat].union(credits_frame[feat].unique())\n",
    "train_lens = np.hstack(train_lens)\n",
    "\n",
    "for step in tqdm.tqdm(range(0, 2, 2),\n",
    "                     desc=\"Count statistics on test data\"):\n",
    "        credits_frame = read_parquet_dataset_from_local(TEST_DATA_PATH, step, 2, verbose=True)\n",
    "        seq_lens = credits_frame.groupby(\"id\").agg(seq_len=(\"rn\", \"max\"))[\"seq_len\"].values\n",
    "        test_lens.extend(seq_lens)\n",
    "        credits_frame.drop(columns=[\"id\", \"rn\"], inplace=True)\n",
    "        for feat in credits_frame.columns.values:\n",
    "            uniques[feat] = uniques[feat].union(credits_frame[feat].unique())\n",
    "test_lens = np.hstack(test_lens)\n",
    "uniques = dict(uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Чтобы сразу убедиться, что посчитанные статистики интересные и полезные, построим графики распределений длин кредитных историй в тренировочной и тестовой выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "train_len_counter = pd.Series(Counter(train_lens)).sort_index()\n",
    "test_len_counter = pd.Series(Counter(test_lens)).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 46 artists>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6), nrows=1)\n",
    "ax.bar(train_len_counter.index.values, train_len_counter.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 46 artists>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6), nrows=1)\n",
    "ax.bar(test_len_counter.index.values, test_len_counter.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 57)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lens.max(), test_lens.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Один из аргументов в функции `dataset_preprocessing_utils.create_padded_buckets` &ndash; `bucket_info` &ndash; словарь, где для конкретной длины последовательности указано до какой длины нужно делать паддинг. Для данного бэйзлайна возьмем простое разбиение на 43 бакета: \n",
    "| Длина последовательности | Длина после паддинга |\n",
    "| :-: | :-: \n",
    "| 1 &ndash; 40 | без изменений |\n",
    "| 41 &ndash; 45 | 45 |\n",
    "| 46 &ndash; 50 | 50 |\n",
    "| 51 &ndash; 58 | 58 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 11: 11,\n",
       " 12: 12,\n",
       " 13: 13,\n",
       " 14: 14,\n",
       " 15: 15,\n",
       " 16: 16,\n",
       " 17: 17,\n",
       " 18: 18,\n",
       " 19: 19,\n",
       " 20: 20,\n",
       " 21: 21,\n",
       " 22: 22,\n",
       " 23: 23,\n",
       " 24: 24,\n",
       " 25: 25,\n",
       " 26: 26,\n",
       " 27: 27,\n",
       " 28: 28,\n",
       " 29: 29,\n",
       " 30: 30,\n",
       " 31: 31,\n",
       " 32: 32,\n",
       " 33: 33,\n",
       " 34: 34,\n",
       " 35: 35,\n",
       " 36: 36,\n",
       " 37: 37,\n",
       " 38: 38,\n",
       " 39: 39,\n",
       " 40: 40,\n",
       " 41: 45,\n",
       " 42: 45,\n",
       " 43: 45,\n",
       " 44: 45,\n",
       " 45: 45,\n",
       " 46: 50,\n",
       " 47: 50,\n",
       " 48: 50,\n",
       " 49: 50,\n",
       " 50: 50,\n",
       " 51: 58,\n",
       " 52: 58,\n",
       " 53: 58,\n",
       " 54: 58,\n",
       " 55: 58,\n",
       " 56: 58,\n",
       " 57: 58,\n",
       " 58: 58}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_ = list(range(1, 59)) \n",
    "lens_ = list(range(1, 41)) + [45] * 5 + [50] * 5 + [58] * 8\n",
    "bucket_info = dict(zip(keys_, lens_))\n",
    "bucket_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Так же рассмотрим уникальные значения признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: pre_since_opened, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_since_confirmed, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}\n",
      "Feature: pre_pterm, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}\n",
      "Feature: pre_fterm, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}\n",
      "Feature: pre_till_pclose, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}\n",
      "Feature: pre_till_fclose, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}\n",
      "Feature: pre_loans_credit_limit, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_loans_next_pay_summ, unique values: {0, 1, 2, 3, 4, 5, 6}\n",
      "Feature: pre_loans_outstanding, unique values: {1, 2, 3, 4, 5}\n",
      "Feature: pre_loans_total_overdue, unique values: {0}\n",
      "Feature: pre_loans_max_overdue_sum, unique values: {1, 2, 3}\n",
      "Feature: pre_loans_credit_cost_rate, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13}\n",
      "Feature: pre_loans5, unique values: {0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16}\n",
      "Feature: pre_loans530, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_loans3060, unique values: {1, 2, 3, 5, 6, 7, 8, 9}\n",
      "Feature: pre_loans6090, unique values: {1, 2, 3, 4, 5}\n",
      "Feature: pre_loans90, unique values: {1, 2, 3, 8, 10, 13, 14, 18, 19}\n",
      "Feature: is_zero_loans5, unique values: {0, 1}\n",
      "Feature: is_zero_loans530, unique values: {0, 1}\n",
      "Feature: is_zero_loans3060, unique values: {0, 1}\n",
      "Feature: is_zero_loans6090, unique values: {0, 1}\n",
      "Feature: is_zero_loans90, unique values: {0, 1}\n",
      "Feature: pre_util, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_over2limit, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: pre_maxover2limit, unique values: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "Feature: is_zero_util, unique values: {0, 1}\n",
      "Feature: is_zero_over2limit, unique values: {0, 1}\n",
      "Feature: is_zero_maxover2limit, unique values: {0, 1}\n",
      "Feature: enc_paym_0, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_1, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_2, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_3, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_4, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_5, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_6, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_7, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_8, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_9, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_10, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_11, unique values: {1, 2, 3, 4}\n",
      "Feature: enc_paym_12, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_13, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_14, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_15, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_16, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_17, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_18, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_19, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_20, unique values: {1, 2, 3, 4}\n",
      "Feature: enc_paym_21, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_22, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_23, unique values: {0, 1, 2, 3}\n",
      "Feature: enc_paym_24, unique values: {1, 2, 3, 4}\n",
      "Feature: enc_loans_account_holder_type, unique values: {0, 1, 2, 3, 4, 5, 6}\n",
      "Feature: enc_loans_credit_status, unique values: {0, 1, 2, 3, 4, 5, 6}\n",
      "Feature: enc_loans_credit_type, unique values: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Feature: enc_loans_account_cur, unique values: {0, 1, 2, 3}\n",
      "Feature: pclose_flag, unique values: {0, 1}\n",
      "Feature: fclose_flag, unique values: {0, 1}\n"
     ]
    }
   ],
   "source": [
    "for feat, uniq in uniques.items():\n",
    "    print(f\"Feature: {feat}, unique values: {uniq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Поскольку паддинг будет производиться нулями, а категориальные признаки закодированы, начиная с 0, перед паддингом будем сдвигать все значения на 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Вся описанная выше предобработка данных реализована в виде функции `create_buckets_from_credits`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_buckets_from_credits(path_to_dataset, bucket_info, save_to_path, frame_with_ids = None, \n",
    "                                num_parts_to_preprocess_at_once: int = 1, \n",
    "                                num_parts_total=50, has_target=False):\n",
    "    block = 0\n",
    "    for step in tqdm.notebook.tqdm(range(0, num_parts_total, num_parts_to_preprocess_at_once),\n",
    "                     desc=\"Preparing credit data\"):\n",
    "        credits_frame = read_parquet_dataset_from_local(path_to_dataset, step, num_parts_to_preprocess_at_once, verbose=True)\n",
    "        credits_frame.loc[:, features] += 1       \n",
    "        seq = transform_credits_to_sequences(credits_frame)\n",
    "        print(\"Transforming credits to sequences is done.\")\n",
    "        \n",
    "        if frame_with_ids is not None:\n",
    "            seq = seq.merge(frame_with_ids, on=\"id\")\n",
    "\n",
    "        block_as_str = str(block)\n",
    "        if len(block_as_str) == 1:\n",
    "            block_as_str = \"00\" + block_as_str\n",
    "        else:\n",
    "            block_as_str = \"0\" + block_as_str\n",
    "            \n",
    "        processed_fragment =  create_padded_buckets(seq, bucket_info=bucket_info, has_target=has_target, \n",
    "                                                    save_to_file_path=os.path.join(save_to_path, \n",
    "                                                                                   f\"processed_chunk_{block_as_str}.pkl\"))\n",
    "        block += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Разобьем обучающие данные на тренировочную и валидационную выборки. Воспользуемся самым простым способом &ndash; для валидации случайным образом выберем 10% обучающих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18748, 2), (2084, 2))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val = train_test_split(train_target, random_state=42, test_size=0.1)\n",
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_BUCKETS_PATH = \"/trinity/home/team08/workspace/main_project/train_buckets_rnn\"\n",
    "# VAL_BUCKETS_PATH = \"/trinity/home/team08/workspace/main_project/val_buckets_rnn\"\n",
    "# TEST_BUCKETS_PATH = \"/trinity/home/team08/workspace/main_project/test_buckets_rnn\"\n",
    "\n",
    "# TRAIN_BUCKETS_PATH = \"/trinity/home/team08/workspace/data/train_buckets_rnn\"\n",
    "# VAL_BUCKETS_PATH = \"/trinity/home/team08/workspace/data/val_buckets_rnn\"\n",
    "# TEST_BUCKETS_PATH = \"/trinity/home/team08/workspace/data/test_buckets_rnn\"\n",
    "\n",
    "# TRAIN_DATA_PATH = \"/trinity/home/team08/workspace/data/train_data/\"\n",
    "# TEST_DATA_PATH = \"/trinity/home/team08/workspace/data/test_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for buckets_path in [TRAIN_BUCKETS_PATH, VAL_BUCKETS_PATH, TEST_BUCKETS_PATH]:\n",
    "#     !rm -rf $buckets_path\n",
    "#     !mkdir $buckets_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# create_buckets_from_credits(TRAIN_DATA_PATH,\n",
    "#                             bucket_info=bucket_info,\n",
    "#                             save_to_path=TRAIN_BUCKETS_PATH,\n",
    "#                             frame_with_ids=train,\n",
    "#                             num_parts_to_preprocess_at_once=4, \n",
    "#                             num_parts_total=12, has_target=True)\n",
    "\n",
    "# dataset_train = sorted([os.path.join(TRAIN_BUCKETS_PATH, x) for x in os.listdir(TRAIN_BUCKETS_PATH)])\n",
    "# dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create_buckets_from_credits(TRAIN_DATA_PATH,\n",
    "#                             bucket_info=bucket_info,\n",
    "#                             save_to_path=VAL_BUCKETS_PATH,\n",
    "#                             frame_with_ids=val,\n",
    "#                             num_parts_to_preprocess_at_once=4, \n",
    "#                             num_parts_total=12, has_target=True)\n",
    "\n",
    "# dataset_val = sorted([os.path.join(VAL_BUCKETS_PATH, x) for x in os.listdir(VAL_BUCKETS_PATH)])\n",
    "# dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# create_buckets_from_credits(TEST_DATA_PATH,\n",
    "#                             bucket_info=bucket_info,\n",
    "#                             save_to_path=TEST_BUCKETS_PATH, num_parts_to_preprocess_at_once=2, \n",
    "#                             num_parts_total=2)\n",
    "\n",
    "# dataset_test = sorted([os.path.join(TEST_BUCKETS_PATH, x) for x in os.listdir(TEST_BUCKETS_PATH)])\n",
    "# dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Для создания модели будем использовать фреймворк `torch`. В нем есть все, чтобы писать произвольные сложные архитектуры и быстро экспериментировать. Для того, чтобы мониторить и логировать весь процесс во время обучения сетей, рекомендуется использовать надстройки над данным фреймворком, например, `lightning`.\n",
    "\n",
    "* В бейзлайне мы предлагаем базовые компоненты, чтобы можно было обучать нейронную сеть и отслеживать ее качество. Для этого вам предоставлены следующие функции:\n",
    "    * `data_generators.batches_generator` &ndash; функция-генератор, итеративно возвращает батчи, поддерживает батчи для `tensorflow.keras` и `torch.nn.Module` моделей. В зависимости от флага `is_train` может быть использована для генерации батчей на train/val/test стадии.\n",
    "    * функция `pytorch_training.train_epoch` &ndash; обучает модель одну эпоху.\n",
    "    * функция `pytorch_training.eval_model` &ndash; проверяет качество модели на отложенной выборке и возвращает roc_auc_score.\n",
    "    * функция `pytorch_training.inference` &ndash; делает предикты на новых данных и готовит фрейм для проверяющей системы.\n",
    "    * класс `training_aux.EarlyStopping` &ndash; реализует early_stopping, сохраняя лучшую модель. Пример использования приведен ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "###from data_generators import batches_generator\n",
    "\n",
    "\n",
    "\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "\n",
    "def batches_generator(list_of_paths: List[str], batch_size: int = 32, shuffle: bool = False,\n",
    "                      is_infinite: bool = False, verbose: bool = False, device: torch.device = None,\n",
    "                      output_format: str = \"torch\", is_train: bool = True):\n",
    "    \"\"\"\n",
    "    Создает батчи на вход рекуррентных нейронных сетей, реализованных на фреймворках tensorflow и pytorch.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    list_of_paths: List[str]\n",
    "        Список путей до файлов с предобработанными последовательностями.\n",
    "    batch_size: int, default=32\n",
    "        Размер батча.\n",
    "    shuffle: bool, default=False\n",
    "        Перемешивать ли данные перед генерацией батчей.\n",
    "    is_infinite: bool, default=False\n",
    "        Должен ли генератор быть бесконечным.\n",
    "    verbose: bool, default=False\n",
    "        Печатать ли имя текущего обрабатываемого файла.\n",
    "    device: torch.device, default=None\n",
    "        Девайс, на который переместить данные при ``output_format``=\"torch\". Игнорируется, если ``output_format``=\"tf\".\n",
    "    output_format: str, default=\"torch\"\n",
    "        Формат возвращаемых данных. Допустимые значения: \"torch\", \"tf\".\n",
    "        Если \"torch\", то возвращает словарь, с ключами \"id_\", \"features\" и \"label\", если is_train=True,\n",
    "        и содержащий идентификаторы заявок, признаки и тагрет соответственно.\n",
    "        Признаки и таргет помещаются на девайс, указанный в ``device``.\n",
    "        Если \"tf\", то возращает кортеж (признаки, таргет), если ``is_train``=True, и кортеж (признаки, идентификаторы заявок) иначе.\n",
    "    is_train: bool, default=True\n",
    "        Используется ли генератор для обучения модели или для инференса.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    ----------------------\n",
    "    result: dict or tuple\n",
    "        Выходной словарь или кортеж в зависимости от параметра ``output_format``.\n",
    "    \"\"\"\n",
    "    if output_format not in [\"torch\", \"tf\"]:\n",
    "        raise ValueError(\"Unknown format. Please choose one of the following formats: \\\"torch\\\", \\\"tf\\\"\")\n",
    "\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(list_of_paths)\n",
    "\n",
    "        for path in list_of_paths:\n",
    "            if verbose:\n",
    "                print(f\"Reading {path}\")\n",
    "\n",
    "            with open(path, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "\n",
    "            ids, padded_sequences, targets = data[\"id\"], data[\"padded_sequences\"], data[\"target\"]\n",
    "            indices = np.arange(len(ids))\n",
    "            if shuffle:\n",
    "                np.random.shuffle(indices)\n",
    "                ids = ids[indices]\n",
    "                padded_sequences = padded_sequences[indices]\n",
    "                if is_train:\n",
    "                    targets = targets[indices]\n",
    "\n",
    "            for idx in range(len(ids)):\n",
    "                bucket_ids = ids[idx]\n",
    "                bucket = padded_sequences[idx]\n",
    "                if is_train:\n",
    "                    bucket_targets = targets[idx]\n",
    "\n",
    "                for jdx in range(0, len(bucket), batch_size):\n",
    "                    batch_ids = bucket_ids[jdx: jdx + batch_size]\n",
    "                    batch_sequences = bucket[jdx: jdx + batch_size]\n",
    "                    if is_train:\n",
    "                        batch_targets = bucket_targets[jdx: jdx + batch_size]\n",
    "\n",
    "                    if output_format == \"tf\":\n",
    "                        batch_sequences = [batch_sequences[:, i] for i in range(len(features))]\n",
    "\n",
    "                        if is_train:\n",
    "                            yield batch_sequences, batch_targets\n",
    "                        else:\n",
    "                            yield batch_sequences, batch_ids\n",
    "                    else:\n",
    "                        batch_sequences = [torch.LongTensor(batch_sequences[:, i]).to(device) for i in range(len(features))]\n",
    "                        if is_train:\n",
    "                            yield dict(id_=batch_ids,\n",
    "                                       features=batch_sequences,\n",
    "                                       label=torch.LongTensor(batch_targets).to(device))\n",
    "                        else:\n",
    "                            yield dict(id_=batch_ids,\n",
    "                                       features=batch_sequences)\n",
    "        if not is_infinite:\n",
    "            break\n",
    "\n",
    "\n",
    "###from pytorch_training import train_epoch, eval_model, inference\n",
    "\n",
    "\n",
    "from typing import List\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(model: torch.nn.Module, optimizer: torch.optim.Optimizer, dataset_train: List[str],\n",
    "                batch_size: int = 64, shuffle: bool = True, print_loss_every_n_batches: int = 500,\n",
    "                device: torch.device = None):\n",
    "    \"\"\"\n",
    "    Делает одну эпоху обучения модели, логируя промежуточные значения функции потерь.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    model: torch.nn.Module\n",
    "        Обучаемая модель.\n",
    "    optimizer: torch.optim.Optimizer\n",
    "        Оптимизатор.\n",
    "    dataset_train: List[str]\n",
    "        Список путей до файлов с предобработанными последовательностями.\n",
    "    batch_size: int, default=64\n",
    "        Размер батча.\n",
    "    shuffle: bool, default=False\n",
    "        Перемешивать ли данные перед подачей в модель.\n",
    "    print_loss_every_n_batches: int, default=500\n",
    "        Число батчей.\n",
    "    device: torch.device, default=None\n",
    "        Девайс, на который переместить данные.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    ----------------------\n",
    "    None\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    loss_function = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    losses = torch.LongTensor().to(device)\n",
    "    samples_counter = 0\n",
    "    train_generator = batches_generator(dataset_train, batch_size=batch_size, shuffle=shuffle,\n",
    "                                        device=device, is_train=True, output_format=\"torch\")\n",
    "\n",
    "    for num_batch, batch in tqdm_notebook(enumerate(train_generator, start=1), desc=\"Training\"):\n",
    "        output = torch.flatten(model(batch[\"features\"]))\n",
    "        batch_loss = loss_function(output, batch[\"label\"].float())\n",
    "        batch_loss.mean().backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        samples_counter += batch_loss.size(0)\n",
    "\n",
    "        losses = torch.cat([losses, batch_loss], dim=0)\n",
    "        if num_batch % print_loss_every_n_batches == 0:\n",
    "            print(f\"Batches {num_batch - print_loss_every_n_batches + 1} - {num_batch} loss:\"\n",
    "                  f\"{losses[-samples_counter:].mean()}\", end=\"\\r\")\n",
    "            samples_counter = 0\n",
    "\n",
    "    print(f\"Training loss after epoch: {losses.mean()}\", end=\"\\r\")\n",
    "\n",
    "\n",
    "def eval_model(model: torch.nn.Module, dataset_val: List[str], batch_size: int = 32, device: torch.device = None) -> float:\n",
    "    \"\"\"\n",
    "    Скорит выборку моделью и вычисляет метрику ROC AUC.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    model: torch.nn.Module\n",
    "        Модель, которой необходимо проскорить выборку.\n",
    "    dataset_val: List[str]\n",
    "        Список путей до файлов с предобработанными последовательностями.\n",
    "    batch_size: int, default=32\n",
    "        Размер батча.\n",
    "    device: torch.device, default=None\n",
    "        Девайс, на который переместить данные.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    ----------------------\n",
    "    auc: float\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    val_generator = batches_generator(dataset_val, batch_size=batch_size, shuffle=False,\n",
    "                                      device=device, is_train=True, output_format=\"torch\")\n",
    "\n",
    "    for batch in tqdm_notebook(val_generator, desc=\"Evaluating model\"):\n",
    "        targets.extend(batch[\"label\"].detach().cpu().numpy().flatten())\n",
    "        output = model(batch[\"features\"])\n",
    "        preds.extend(output.detach().cpu().numpy().flatten())\n",
    "\n",
    "    return roc_auc_score(targets, preds)\n",
    "\n",
    "\n",
    "def inference(model: torch.nn.Module, dataset_test: List[str], batch_size: int = 32, device: torch.device = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Скорит выборку моделью.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    model: torch.nn.Module\n",
    "        Модель, которой необходимо проскорить выборку.\n",
    "    dataset_test: List[str]\n",
    "        Список путей до файлов с предобработанными последовательностями.\n",
    "    batch_size: int, default=32\n",
    "        Размер батча.\n",
    "    device: torch.device, default=None\n",
    "        Девайс, на который переместить данные.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    ----------------------\n",
    "    scores: pandas.DataFrame\n",
    "        Датафрейм с двумя колонками: \"id\" - идентификатор заявки и \"score\" - скор модели.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    ids = []\n",
    "    test_generator = batches_generator(dataset_test, batch_size=batch_size, shuffle=False,\n",
    "                                       verbose=False, device=device, is_train=False,\n",
    "                                       output_format=\"torch\")\n",
    "\n",
    "    for batch in tqdm_notebook(test_generator, desc=\"Test predictions\"):\n",
    "        ids.extend(batch[\"id_\"])\n",
    "        output = model(batch[\"features\"])\n",
    "        preds.extend(output.detach().cpu().numpy().flatten())\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"id\": ids,\n",
    "        \"score\": preds\n",
    "    })\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Останавливает обучение модели, если валидационная метрика не улучшается в течение заданного числа эпох.\n",
    "\n",
    "    Параметры:\n",
    "    ----------\n",
    "    patience: int, default=7\n",
    "        Допустимое число эпох без улучшения валидационной метрики.\n",
    "        Валидационная метрика должна улучшаться как минимум каждые ``patience`` эпох, иначе обучение останавливается.\n",
    "    mode: str, default=\"min\"\n",
    "        Режим работы. Допустимые значения: \"min\", \"max\" - минимизация или максимизация целевой метрики соответственно.\n",
    "    verbose: bool, default=False\n",
    "        Печатать ли сообщение при каждом улучшении валидационной метрики.\n",
    "    delta: int, default=0\n",
    "        Минимальное изменение контролируемой метрики, которое можно считать улучшением.\n",
    "    save_path: str, default=\"checkpoint.hdf5\"\n",
    "        Путь до файла, в который необходимо сохранять лучшую модель.\n",
    "    metric_name: str, default=None\n",
    "        Имя метрики.\n",
    "    save_format: str, default=\"torch\"\n",
    "        Формат модели. Допустимые значения: \"torch\", \"tf\" - для моделей на фреймворках pytorch и tensorflow.keras соответственно.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience=7, mode='min', verbose=False, delta=0, save_path='checkpoint.hdf5', metric_name=None, save_format='torch'):\n",
    "        if mode not in [\"min\", \"max\"]:\n",
    "            raise ValueError(f\"Unrecognized mode: {mode}! Please choose one of the following modes: \\\"min\\\", \\\"max\\\"\")\n",
    "\n",
    "        if save_format not in [\"torch\", \"tf\"]:\n",
    "            raise ValueError(f\"Unrecognized format: {save_format}! Please choose one of the following formats: \\\"torch\\\", \\\"tf\\\"\")\n",
    "\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_prev_score = np.Inf if mode == \"min\" else -np.Inf\n",
    "        self.delta = delta\n",
    "        self.save_path = save_path\n",
    "        self.metric_name = \"metric\" if not metric_name else metric_name\n",
    "        self.save_format = save_format\n",
    "\n",
    "    def __call__(self, metric_value, model):\n",
    "\n",
    "        score = -metric_value if self.mode == \"min\" else metric_value\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(metric_value, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(\n",
    "                f\"No imporvement in validation {self.metric_name}. Current: {score:.6f}. Current best: {self.best_score:.6f}\")\n",
    "            print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(metric_value, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, metric_value: float, model: torch.nn.Module or tensorflow.keras.Model):\n",
    "        \"\"\"\n",
    "        Cохраняет модель, если валидационная метрика улучшилась.\n",
    "\n",
    "        Параметры:\n",
    "        ----------\n",
    "        metric_value: float\n",
    "            Значение валидационной метрики.\n",
    "        model: torch.nn.Module or tensorflow.keras.Model\n",
    "            Обучаемая модель.\n",
    "\n",
    "        Возвращаемое значение:\n",
    "        ----------------------\n",
    "        None\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f\"Validation {self.metric_name} improved ({self.best_prev_score:.6f} --> {metric_value:.6f}).  Saving model...\")\n",
    "        if self.save_format == \"tf\":\n",
    "            model.save_weights(self.save_path)\n",
    "        else:\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "\n",
    "        self.best_prev_score = metric_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Все признаки, описывающие кредитную историю клиентов &ndash; категориальные. Для их представления в модели используем категориальные эмбеддинги. Для этого нужно каждому категориальному признаку задать размерность латентного пространства. Используем [формулу](https://forums.fast.ai/t/size-of-embedding-for-categorical-variables/42608) из библиотеки `fast.ai`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embed_dim(n_cat: int) -> int:\n",
    "    return min(600, round(1.6 * n_cat**0.56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pre_since_opened': (20, 9),\n",
       " 'pre_since_confirmed': (18, 8),\n",
       " 'pre_pterm': (18, 8),\n",
       " 'pre_fterm': (17, 8),\n",
       " 'pre_till_pclose': (17, 8),\n",
       " 'pre_till_fclose': (16, 8),\n",
       " 'pre_loans_credit_limit': (20, 9),\n",
       " 'pre_loans_next_pay_summ': (7, 5),\n",
       " 'pre_loans_outstanding': (6, 4),\n",
       " 'pre_loans_total_overdue': (1, 2),\n",
       " 'pre_loans_max_overdue_sum': (4, 3),\n",
       " 'pre_loans_credit_cost_rate': (14, 7),\n",
       " 'pre_loans5': (17, 8),\n",
       " 'pre_loans530': (20, 9),\n",
       " 'pre_loans3060': (10, 6),\n",
       " 'pre_loans6090': (6, 4),\n",
       " 'pre_loans90': (20, 9),\n",
       " 'is_zero_loans5': (2, 2),\n",
       " 'is_zero_loans530': (2, 2),\n",
       " 'is_zero_loans3060': (2, 2),\n",
       " 'is_zero_loans6090': (2, 2),\n",
       " 'is_zero_loans90': (2, 2),\n",
       " 'pre_util': (20, 9),\n",
       " 'pre_over2limit': (20, 9),\n",
       " 'pre_maxover2limit': (20, 9),\n",
       " 'is_zero_util': (2, 2),\n",
       " 'is_zero_over2limit': (2, 2),\n",
       " 'is_zero_maxover2limit': (2, 2),\n",
       " 'enc_paym_0': (4, 3),\n",
       " 'enc_paym_1': (4, 3),\n",
       " 'enc_paym_2': (4, 3),\n",
       " 'enc_paym_3': (4, 3),\n",
       " 'enc_paym_4': (4, 3),\n",
       " 'enc_paym_5': (4, 3),\n",
       " 'enc_paym_6': (4, 3),\n",
       " 'enc_paym_7': (4, 3),\n",
       " 'enc_paym_8': (4, 3),\n",
       " 'enc_paym_9': (4, 3),\n",
       " 'enc_paym_10': (4, 3),\n",
       " 'enc_paym_11': (5, 4),\n",
       " 'enc_paym_12': (4, 3),\n",
       " 'enc_paym_13': (4, 3),\n",
       " 'enc_paym_14': (4, 3),\n",
       " 'enc_paym_15': (4, 3),\n",
       " 'enc_paym_16': (4, 3),\n",
       " 'enc_paym_17': (4, 3),\n",
       " 'enc_paym_18': (4, 3),\n",
       " 'enc_paym_19': (4, 3),\n",
       " 'enc_paym_20': (5, 4),\n",
       " 'enc_paym_21': (4, 3),\n",
       " 'enc_paym_22': (4, 3),\n",
       " 'enc_paym_23': (4, 3),\n",
       " 'enc_paym_24': (5, 4),\n",
       " 'enc_loans_account_holder_type': (7, 5),\n",
       " 'enc_loans_credit_status': (7, 5),\n",
       " 'enc_loans_credit_type': (8, 5),\n",
       " 'enc_loans_account_cur': (4, 3),\n",
       " 'pclose_flag': (2, 2),\n",
       " 'fclose_flag': (2, 2)}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_projections = {feat: (max(uniq)+1, compute_embed_dim(max(uniq)+1)) for feat, uniq in uniques.items()}\n",
    "embedding_projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Реализуем модель. Все входные признаки представим в виде эмбеддингов, сконкатенируем, чтобы получить векторное представление транзакции. Подадим последовательности в `GRU` рекуррентный слой. Используем последнее скрытое состояние в качестве выхода слоя. На основе такого входа построим небольшой `MLP`, выступающий классификатором для целевой задачи. Используем градиентный спуск, чтобы решить оптимизационную задачу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditsRNN(nn.Module):\n",
    "    def __init__(self, features, embedding_projections, rnn_units=128, top_classifier_units=32):\n",
    "        super(CreditsRNN, self).__init__()\n",
    "        self._credits_cat_embeddings = nn.ModuleList([self._create_embedding_projection(*embedding_projections[feature]) \n",
    "                                                          for feature in features])\n",
    "                        \n",
    "        self._gru = nn.GRU(input_size=sum([embedding_projections[x][1] for x in features]),\n",
    "                             hidden_size=rnn_units, batch_first=True, bidirectional=False)\n",
    "        self._hidden_size = rnn_units\n",
    "        self._top_classifier = nn.Linear(in_features=rnn_units, out_features=top_classifier_units)\n",
    "        self._intermediate_activation = nn.ReLU()\n",
    "        self._head = nn.Linear(in_features=top_classifier_units, out_features=1)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        batch_size = features[0].shape[0]\n",
    "        embeddings = [embedding(features[i]) for i, embedding in enumerate(self._credits_cat_embeddings)]\n",
    "        concated_embeddings = torch.cat(embeddings, dim=-1)\n",
    "        \n",
    "        _, last_hidden = self._gru(concated_embeddings)\n",
    "        last_hidden = torch.reshape(last_hidden.permute(1, 2, 0), shape=(batch_size, self._hidden_size))\n",
    "                                \n",
    "        classification_hidden = self._top_classifier(last_hidden)\n",
    "        activation = self._intermediate_activation(classification_hidden)\n",
    "        raw_output = self._head(activation)\n",
    "        return raw_output\n",
    "    \n",
    "    @classmethod\n",
    "    def _create_embedding_projection(cls, cardinality, embed_size, add_missing=True, padding_idx=0):\n",
    "        add_missing = 1 if add_missing else 0\n",
    "        return nn.Embedding(num_embeddings=cardinality+add_missing, embedding_dim=embed_size, padding_idx=padding_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /trinity/home/team08/workspace/main_project/./checkpoints/\n",
    "!mkdir /trinity/home/team08/workspace/main_project/./checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/trinity/home/team08/workspace/main_project/./checkpoints/pytorch_baseline': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r /trinity/home/team08/workspace/main_project/./checkpoints/pytorch_baseline\n",
    "!mkdir /trinity/home/team08/workspace/main_project/./checkpoints/pytorch_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Для того, чтобы детектировать переобучение используем EarlyStopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_checkpoints = \"/trinity/home/team08/workspace/main_project/./checkpoints/pytorch_baseline/\"\n",
    "es = EarlyStopping(patience=3, mode=\"max\", verbose=True, save_path=os.path.join(path_to_checkpoints, \"best_checkpoint.pt\"), \n",
    "                   metric_name=\"ROC-AUC\", save_format=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train_batch_size = 128\n",
    "val_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CreditsRNN(features, embedding_projections).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditsRNN(\n",
       "  (_credits_cat_embeddings): ModuleList(\n",
       "    (0): Embedding(21, 9, padding_idx=0)\n",
       "    (1-2): 2 x Embedding(19, 8, padding_idx=0)\n",
       "    (3-4): 2 x Embedding(18, 8, padding_idx=0)\n",
       "    (5): Embedding(17, 8, padding_idx=0)\n",
       "    (6): Embedding(21, 9, padding_idx=0)\n",
       "    (7): Embedding(8, 5, padding_idx=0)\n",
       "    (8): Embedding(7, 4, padding_idx=0)\n",
       "    (9): Embedding(2, 2, padding_idx=0)\n",
       "    (10): Embedding(5, 3, padding_idx=0)\n",
       "    (11): Embedding(15, 7, padding_idx=0)\n",
       "    (12): Embedding(18, 8, padding_idx=0)\n",
       "    (13): Embedding(21, 9, padding_idx=0)\n",
       "    (14): Embedding(11, 6, padding_idx=0)\n",
       "    (15): Embedding(7, 4, padding_idx=0)\n",
       "    (16): Embedding(21, 9, padding_idx=0)\n",
       "    (17-21): 5 x Embedding(3, 2, padding_idx=0)\n",
       "    (22-24): 3 x Embedding(21, 9, padding_idx=0)\n",
       "    (25-27): 3 x Embedding(3, 2, padding_idx=0)\n",
       "    (28-38): 11 x Embedding(5, 3, padding_idx=0)\n",
       "    (39): Embedding(6, 4, padding_idx=0)\n",
       "    (40-47): 8 x Embedding(5, 3, padding_idx=0)\n",
       "    (48): Embedding(6, 4, padding_idx=0)\n",
       "    (49-51): 3 x Embedding(5, 3, padding_idx=0)\n",
       "    (52): Embedding(6, 4, padding_idx=0)\n",
       "    (53-54): 2 x Embedding(8, 5, padding_idx=0)\n",
       "    (55): Embedding(9, 5, padding_idx=0)\n",
       "    (56): Embedding(5, 3, padding_idx=0)\n",
       "    (57-58): 2 x Embedding(3, 2, padding_idx=0)\n",
       "  )\n",
       "  (_gru): GRU(258, 128, batch_first=True)\n",
       "  (_top_classifier): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (_intermediate_activation): ReLU()\n",
       "  (_head): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lr=1e-3, params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/trinity/home/team08/workspace/data/train_buckets_rnn/processed_chunk_000.pkl',\n",
       " '/trinity/home/team08/workspace/data/train_buckets_rnn/processed_chunk_002.pkl',\n",
       " '/trinity/home/team08/workspace/data/train_buckets_rnn/processed_chunk_001.pkl']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Запустим цикл обучения, каждую эпоху будем логировать лосс, а так же ROC-AUC на валидации и на обучении. Будем сохрнаять веса после каждой эпохи, а так же лучшие с помощью early_stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_313592/1505826781.py:146: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for num_batch, batch in tqdm_notebook(enumerate(train_generator, start=1), desc=\"Training\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bde9531d944ab8a5497782f0077f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
      "Cell \u001b[0;32mIn[172], line 146\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, dataset_train, batch_size, shuffle, print_loss_every_n_batches, device)\u001b[0m\n\u001b[1;32m    142\u001b[0m samples_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    143\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m batches_generator(dataset_train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[1;32m    144\u001b[0m                                     device\u001b[38;5;241m=\u001b[39mdevice, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_batch, batch \u001b[38;5;129;01min\u001b[39;00m tqdm_notebook(\u001b[38;5;28menumerate\u001b[39m(train_generator, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    147\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(model(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    148\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m loss_function(output, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/notebook.py:259\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[172], line 66\u001b[0m, in \u001b[0;36mbatches_generator\u001b[0;34m(list_of_paths, batch_size, shuffle, is_infinite, verbose, device, output_format, is_train)\u001b[0m\n\u001b[1;32m     64\u001b[0m     padded_sequences \u001b[38;5;241m=\u001b[39m padded_sequences[indices]\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_train:\n\u001b[0;32m---> 66\u001b[0m         targets \u001b[38;5;241m=\u001b[39m \u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ids)):\n\u001b[1;32m     69\u001b[0m     bucket_ids \u001b[38;5;241m=\u001b[39m ids[idx]\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting epoch {epoch+1}\")\n",
    "    train_epoch(model, optimizer, dataset_train, batch_size=train_batch_size, \n",
    "                shuffle=True, print_loss_every_n_batches=500, device=device)\n",
    "    \n",
    "    val_roc_auc = eval_model(model, dataset_val, batch_size=val_batch_size, device=device)\n",
    "    es(val_roc_auc, model)\n",
    "    \n",
    "    if es.early_stop:\n",
    "        print(\"Early stopping reached. Stop training...\")\n",
    "        break\n",
    "    torch.save(model.state_dict(), os.path.join(path_to_checkpoints, f\"epoch_{epoch+1}_val_{val_roc_auc:.3f}.pt\"))\n",
    "    \n",
    "    train_roc_auc = eval_model(model, dataset_train, batch_size=val_batch_size, device=device)\n",
    "    print(f\"Epoch {epoch+1} completed. Train ROC AUC: {train_roc_auc}, val ROC AUC: {val_roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Подготовим посылку в проверяющую систему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/trinity/home/team08/workspace/data/./checkpoints/pytorch_baseline/'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(path_to_checkpoints, \"best_checkpoint.pt\"), map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_checkpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_checkpoint.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1116\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1112\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39mUntypedStorage)\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1116\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1117\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1121\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 217\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:173\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    171\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on CUDA device \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    174\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but torch.cuda.device_count() is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    175\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.load with map_location to map your storages \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    176\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto an existing device.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m device\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on CUDA device 0 but torch.cuda.device_count() is 0. Please use torch.load with map_location to map your storages to an existing device."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(path_to_checkpoints, \"best_checkpoint.pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6370c8ce7d34ee3a350c111ff98aa68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test predictions: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = inference(model, dataset_test, batch_size=128, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd581b1e41840e89118419930b17e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test predictions: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/trinity/home/team08/workspace/data/train_buckets_rnn/processed_chunk_002.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_preds \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train_preds\n",
      "File \u001b[0;32m~/rnn_baseline/pytorch_training.py:123\u001b[0m, in \u001b[0;36minference\u001b[0;34m(model, dataset_test, batch_size, device)\u001b[0m\n\u001b[1;32m    118\u001b[0m ids \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    119\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m batches_generator(dataset_test, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m                                    verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    121\u001b[0m                                    output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm_notebook(test_generator, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest predictions\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    124\u001b[0m     ids\u001b[38;5;241m.\u001b[39mextend(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    125\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/notebook.py:259\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/rnn_baseline/data_generators.py:65\u001b[0m, in \u001b[0;36mbatches_generator\u001b[0;34m(list_of_paths, batch_size, shuffle, is_infinite, verbose, device, output_format, is_train)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     66\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     68\u001b[0m ids, padded_sequences, targets \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpadded_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/trinity/home/team08/workspace/data/train_buckets_rnn/processed_chunk_002.pkl'"
     ]
    }
   ],
   "source": [
    "train_preds = inference(model, dataset_train, batch_size=128, device=device)\n",
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000014</td>\n",
       "      <td>-3.209836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000020</td>\n",
       "      <td>-1.469409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000027</td>\n",
       "      <td>-3.320151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000043</td>\n",
       "      <td>-1.958419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000049</td>\n",
       "      <td>-3.275137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     score\n",
       "0  3000014 -3.209836\n",
       "1  3000020 -1.469409\n",
       "2  3000027 -3.320151\n",
       "3  3000043 -1.958419\n",
       "4  3000049 -3.275137"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.to_csv(\"/trinity/home/team08/workspace/rnn_baseline/torch_submission.csv\", index=None) # ~ 0.765 на public test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Test roc-auc: \", roc_auc_score(, test_preds)) \n",
    "# Train roc-auc gb:  0.8790580266970891\n",
    "# val ROC AUC pytorch: 0.7705235440545772"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
